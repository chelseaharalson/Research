--- JobInProgress_0180.java	2008-08-14 15:48:25.000000000 -0400
+++ JobInProgress_0190.java	2008-11-13 22:09:35.000000000 -0500
@@ -30,6 +30,7 @@
 import java.util.Set;
 import java.util.TreeMap;
 import java.util.Vector;
+import java.util.concurrent.atomic.AtomicBoolean;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -37,7 +38,6 @@
 import org.apache.hadoop.fs.LocalFileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.mapred.JobHistory.Values;
-import org.apache.hadoop.mapred.JobTracker.JobTrackerMetrics;
 import org.apache.hadoop.metrics.MetricsContext;
 import org.apache.hadoop.metrics.MetricsRecord;
 import org.apache.hadoop.metrics.MetricsUtil;
@@ -52,15 +52,18 @@
  * ***********************************************************
  */
 class JobInProgress {
-  private static final Log LOG = LogFactory.getLog("org.apache.hadoop.mapred.JobInProgress");
+  static final Log LOG = LogFactory.getLog(JobInProgress.class);
     
   JobProfile profile;
   JobStatus status;
+  Path jobFile = null;
   Path localJobFile = null;
   Path localJarFile = null;
 
   TaskInProgress maps[] = new TaskInProgress[0];
   TaskInProgress reduces[] = new TaskInProgress[0];
+  TaskInProgress cleanup[] = new TaskInProgress[0];
+  TaskInProgress setup[] = new TaskInProgress[0];
   int numMapTasks = 0;
   int numReduceTasks = 0;
   
@@ -71,11 +74,19 @@
   int finishedReduceTasks = 0;
   int failedMapTasks = 0; 
   int failedReduceTasks = 0;
+  // runningMapTasks include speculative tasks, so we need to capture 
+  // speculative tasks separately 
+  int speculativeMapTasks = 0;
+  int speculativeReduceTasks = 0;
   
   int mapFailuresPercent = 0;
   int reduceFailuresPercent = 0;
   int failedMapTIPs = 0;
   int failedReduceTIPs = 0;
+  private volatile boolean launchedCleanup = false;
+  private volatile boolean launchedSetup = false;
+  private volatile boolean jobKilled = false;
+  private volatile boolean jobFailed = false;
 
   JobPriority priority = JobPriority.NORMAL;
   JobTracker jobtracker = null;
@@ -119,17 +130,27 @@
   private Map<String, Integer> trackerToFailuresMap = 
     new TreeMap<String, Integer>();
     
+  //Confine estimation algorithms to an "oracle" class that JIP queries.
+  private ResourceEstimator resourceEstimator; 
+  
   long startTime;
+  long launchTime;
   long finishTime;
+  
+  // Indicates how many times the job got restarted
+  private int restartCount = 0;
 
   private JobConf conf;
-  boolean tasksInited = false;
+  AtomicBoolean tasksInited = new AtomicBoolean(false);
+  private JobInitKillStatus jobInitKillStatus = new JobInitKillStatus();
 
   private LocalFileSystem localFs;
   private JobID jobId;
   private boolean hasSpeculativeMaps;
   private boolean hasSpeculativeReduces;
-
+  private long inputLength = 0;
+  private long maxVirtualMemoryForTask;
+  
   // Per-job counters
   public static enum Counter { 
     NUM_FAILED_MAPS, 
@@ -151,6 +172,19 @@
   // Map of mapTaskId -> no. of fetch failures
   private Map<TaskAttemptID, Integer> mapTaskIdToFetchFailuresMap =
     new TreeMap<TaskAttemptID, Integer>();
+
+  private Object schedulingInfo;
+
+  
+  /**
+   * Create an almost empty JobInProgress, which can be used only for tests
+   */
+  protected JobInProgress(JobID jobid, JobConf conf) {
+    this.conf = conf;
+    this.jobId = jobid;
+    this.numMapTasks = conf.getNumMapTasks();
+    this.numReduceTasks = conf.getNumReduceTasks();
+  }
   
   /**
    * Create a JobInProgress with the given job file, plus a handle
@@ -164,6 +198,7 @@
     this.jobtracker = jobtracker;
     this.status = new JobStatus(jobid, 0.0f, 0.0f, JobStatus.PREP);
     this.startTime = System.currentTimeMillis();
+    status.setStartTime(startTime);
     this.localFs = FileSystem.getLocal(default_conf);
 
     JobConf default_job_conf = new JobConf(default_conf);
@@ -173,12 +208,14 @@
                                                       +"/"+ jobid + ".jar");
     Path sysDir = new Path(this.jobtracker.getSystemDir());
     FileSystem fs = sysDir.getFileSystem(default_conf);
-    Path jobFile = new Path(sysDir, jobid + "/job.xml");
+    jobFile = new Path(sysDir, jobid + "/job.xml");
     fs.copyToLocalFile(jobFile, localJobFile);
     conf = new JobConf(localJobFile);
     this.priority = conf.getJobPriority();
+    this.status.setJobPriority(this.priority);
     this.profile = new JobProfile(conf.getUser(), jobid, 
-                                  jobFile.toString(), url, conf.getJobName());
+                                  jobFile.toString(), url, conf.getJobName(),
+                                  conf.getQueueName());
     String jarFile = conf.getJar();
     if (jarFile != null) {
       fs.copyToLocalFile(new Path(jarFile), localJarFile);
@@ -193,9 +230,6 @@
     this.mapFailuresPercent = conf.getMaxMapTaskFailuresPercent();
     this.reduceFailuresPercent = conf.getMaxReduceTaskFailuresPercent();
         
-    JobHistory.JobInfo.logSubmitted(jobid, conf, jobFile.toString(), 
-                                    System.currentTimeMillis()); 
-        
     MetricsContext metricsContext = MetricsUtil.getContext("mapred");
     this.jobMetrics = MetricsUtil.createRecord(metricsContext, "job");
     this.jobMetrics.setTag("user", conf.getUser());
@@ -210,6 +244,8 @@
     this.runningMapCache = new IdentityHashMap<Node, Set<TaskInProgress>>();
     this.nonRunningReduces = new LinkedList<TaskInProgress>();    
     this.runningReduces = new LinkedHashSet<TaskInProgress>();
+    this.resourceEstimator = new ResourceEstimator(this);
+    this.maxVirtualMemoryForTask = conf.getMaxVirtualMemoryForTask();
   }
 
   /**
@@ -288,15 +324,37 @@
     }
     return cache;
   }
+  
+  /**
+   * Check if the job has been initialized.
+   * @return <code>true</code> if the job has been initialized, 
+   *         <code>false</code> otherwise
+   */
+  public boolean inited() {
+    return tasksInited.get();
+  }
+  
   /**
    * Construct the splits, etc.  This is invoked from an async
    * thread so that split-computation doesn't block anyone.
    */
   public synchronized void initTasks() throws IOException {
-    if (tasksInited) {
+    if (tasksInited.get()) {
       return;
     }
+    synchronized(jobInitKillStatus){
+      if(jobInitKillStatus.killed) {
+        return;
+      }
+      jobInitKillStatus.initStarted = true;
+    }
 
+    // log job info
+    JobHistory.JobInfo.logSubmitted(getJobID(), conf, jobFile.toString(), 
+                                    this.startTime);
+    // log the job priority
+    setPriority(this.priority);
+    
     //
     // read input splits and create a map per a split
     //
@@ -313,30 +371,49 @@
       splitFile.close();
     }
     numMapTasks = splits.length;
+
+
+    // if the number of splits is larger than a configured value
+    // then fail the job.
+    int maxTasks = jobtracker.getMaxTasksPerJob();
+    if (maxTasks > 0 && numMapTasks + numReduceTasks > maxTasks) {
+      throw new IOException(
+                "The number of tasks for this job " + 
+                (numMapTasks + numReduceTasks) +
+                " exceeds the configured limit " + maxTasks);
+    }
+
     maps = new TaskInProgress[numMapTasks];
     for(int i=0; i < numMapTasks; ++i) {
+      inputLength += splits[i].getDataLength();
       maps[i] = new TaskInProgress(jobId, jobFile, 
                                    splits[i], 
                                    jobtracker, conf, this, i);
     }
+    LOG.info("Input size for job "+ jobId + " = " + inputLength);
     if (numMapTasks > 0) { 
       LOG.info("Split info for job:" + jobId);
       nonRunningMapCache = createCache(splits, maxLevel);
     }
         
+    // set the launch time
+    this.launchTime = System.currentTimeMillis();
+
     // if no split is returned, job is considered completed and successful
     if (numMapTasks == 0) {
       // Finished time need to be setted here to prevent this job to be retired
       // from the job tracker jobs at the next retire iteration.
-      this.finishTime = System.currentTimeMillis();
+      this.finishTime = this.launchTime;
+      status.setSetupProgress(1.0f);
       status.setMapProgress(1.0f);
       status.setReduceProgress(1.0f);
+      status.setCleanupProgress(1.0f);
       status.setRunState(JobStatus.SUCCEEDED);
-      tasksInited = true;
-      JobHistory.JobInfo.logStarted(profile.getJobID(), 
-                                    System.currentTimeMillis(), 0, 0);
+      tasksInited.set(true);
+      JobHistory.JobInfo.logInited(profile.getJobID(), 
+                                    this.launchTime, 0, 0);
       JobHistory.JobInfo.logFinished(profile.getJobID(), 
-                                     System.currentTimeMillis(), 0, 0, 0, 0,
+                                     this.finishTime, 0, 0, 0, 0,
                                      getCounters());
       // Special case because the Job is not queued
       JobEndNotifier.registerNotification(this.getJobConf(), this.getStatus());
@@ -355,20 +432,44 @@
       nonRunningReduces.add(reduces[i]);
     }
 
-    // create job specific temporary directory in output path
-    Path outputPath = FileOutputFormat.getOutputPath(conf);
-    if (outputPath != null) {
-      Path tmpDir = new Path(outputPath, MRConstants.TEMP_DIR_NAME);
-      FileSystem fileSys = tmpDir.getFileSystem(conf);
-      if (!fileSys.mkdirs(tmpDir)) {
-        LOG.error("Mkdirs failed to create " + tmpDir.toString());
+    // create cleanup two cleanup tips, one map and one reduce.
+    cleanup = new TaskInProgress[2];
+    // cleanup map tip. This map is doesn't use split. 
+    // Just assign splits[0]
+    cleanup[0] = new TaskInProgress(jobId, jobFile, splits[0], 
+            jobtracker, conf, this, numMapTasks);
+    cleanup[0].setCleanupTask();
+
+    // cleanup reduce tip.
+    cleanup[1] = new TaskInProgress(jobId, jobFile, numMapTasks,
+                       numReduceTasks, jobtracker, conf, this);
+    cleanup[1].setCleanupTask();
+
+    // create two setup tips, one map and one reduce.
+    setup = new TaskInProgress[2];
+    // setup map tip. This map is doesn't use split. 
+    // Just assign splits[0]
+    setup[0] = new TaskInProgress(jobId, jobFile, splits[0], 
+            jobtracker, conf, this, numMapTasks + 1 );
+    setup[0].setSetupTask();
+
+    // setup reduce tip.
+    setup[1] = new TaskInProgress(jobId, jobFile, numMapTasks,
+                       numReduceTasks + 1, jobtracker, conf, this);
+    setup[1].setSetupTask();
+    
+    synchronized(jobInitKillStatus){
+      jobInitKillStatus.initDone = true;
+      if(jobInitKillStatus.killed) {
+        //setup not launched so directly terminate
+        terminateJob(JobStatus.KILLED);
+        return;
       }
     }
-
-    this.status = new JobStatus(status.getJobID(), 0.0f, 0.0f, JobStatus.RUNNING);
-    tasksInited = true;
-        
-    JobHistory.JobInfo.logStarted(profile.getJobID(), System.currentTimeMillis(), numMapTasks, numReduceTasks);
+    
+    tasksInited.set(true);
+    JobHistory.JobInfo.logInited(profile.getJobID(), this.launchTime, 
+                                 numMapTasks, numReduceTasks);
   }
 
   /////////////////////////////////////////////////////
@@ -380,6 +481,9 @@
   public JobStatus getStatus() {
     return status;
   }
+  public synchronized long getLaunchTime() {
+    return launchTime;
+  }
   public long getStartTime() {
     return startTime;
   }
@@ -404,6 +508,14 @@
   public synchronized int finishedReduces() {
     return finishedReduceTasks;
   }
+  public synchronized int pendingMaps() {
+    return numMapTasks - runningMapTasks - failedMapTIPs - 
+    finishedMapTasks + speculativeMapTasks;
+  }
+  public synchronized int pendingReduces() {
+    return numReduceTasks - runningReduceTasks - failedReduceTIPs - 
+    finishedReduceTasks + speculativeReduceTasks;
+  }
   public JobPriority getPriority() {
     return this.priority;
   }
@@ -413,6 +525,37 @@
     } else {
       this.priority = priority;
     }
+    synchronized (this) {
+      status.setJobPriority(priority);
+    }
+    // log and change to the job's priority
+    JobHistory.JobInfo.logJobPriority(jobId, priority);
+  }
+
+  // Accessors for resources.
+  public long getMaxVirtualMemoryForTask() {
+    return maxVirtualMemoryForTask;
+  }
+  
+  // Update the job start/launch time (upon restart) and log to history
+  synchronized void updateJobInfo(long startTime, long launchTime, int count) {
+    // log and change to the job's start/launch time
+    this.startTime = startTime;
+    this.launchTime = launchTime;
+    // change to the job's restart count
+    this.restartCount = count;
+    JobHistory.JobInfo.logJobInfo(jobId, startTime, launchTime, count);
+  }
+
+  /**
+   * Get the number of times the job has restarted
+   */
+  int numRestarts() {
+    return restartCount;
+  }
+  
+  long getInputLength() {
+    return inputLength;
   }
  
   /**
@@ -424,13 +567,56 @@
   }
     
   /**
+   * Get the list of cleanup tasks
+   * @return the array of cleanup tasks for the job
+   */
+  TaskInProgress[] getCleanupTasks() {
+    return cleanup;
+  }
+  
+  /**
+   * Get the list of setup tasks
+   * @return the array of setup tasks for the job
+   */
+  TaskInProgress[] getSetupTasks() {
+    return setup;
+  }
+  
+  /**
    * Get the list of reduce tasks
    * @return the raw array of reduce tasks for this job
    */
   TaskInProgress[] getReduceTasks() {
     return reduces;
   }
-    
+
+  /**
+   * Return the nonLocalRunningMaps
+   * @return
+   */
+  Set<TaskInProgress> getNonLocalRunningMaps()
+  {
+    return nonLocalRunningMaps;
+  }
+  
+  /**
+   * Return the runningMapCache
+   * @return
+   */
+  Map<Node, Set<TaskInProgress>> getRunningMapCache()
+  {
+    return runningMapCache;
+  }
+  
+  /**
+   * Return runningReduces
+   * @return
+   */
+  Set<TaskInProgress> getRunningReduces()
+  {
+    return runningReduces;
+  }
+  
   /**
    * Get the job configuration
    * @return the job's configuration
@@ -442,7 +628,7 @@
   /**
    * Return a vector of completed TaskInProgress objects
    */
-  public Vector<TaskInProgress> reportTasksInProgress(boolean shouldBeMap,
+  public synchronized Vector<TaskInProgress> reportTasksInProgress(boolean shouldBeMap,
                                                       boolean shouldBeComplete) {
     
     Vector<TaskInProgress> results = new Vector<TaskInProgress>();
@@ -459,17 +645,50 @@
     }
     return results;
   }
+  
+  /**
+   * Return a vector of cleanup TaskInProgress objects
+   */
+  public synchronized Vector<TaskInProgress> reportCleanupTIPs(
+                                               boolean shouldBeComplete) {
+    
+    Vector<TaskInProgress> results = new Vector<TaskInProgress>();
+    for (int i = 0; i < cleanup.length; i++) {
+      if (cleanup[i].isComplete() == shouldBeComplete) {
+        results.add(cleanup[i]);
+      }
+    }
+    return results;
+  }
+
+  /**
+   * Return a vector of setup TaskInProgress objects
+   */
+  public synchronized Vector<TaskInProgress> reportSetupTIPs(
+                                               boolean shouldBeComplete) {
+    
+    Vector<TaskInProgress> results = new Vector<TaskInProgress>();
+    for (int i = 0; i < setup.length; i++) {
+      if (setup[i].isComplete() == shouldBeComplete) {
+        results.add(setup[i]);
+      }
+    }
+    return results;
+  }
 
   ////////////////////////////////////////////////////
   // Status update methods
   ////////////////////////////////////////////////////
   public synchronized void updateTaskStatus(TaskInProgress tip, 
                                             TaskStatus status,
-                                            JobTrackerMetrics metrics) {
+                                            JobTrackerInstrumentation metrics) {
 
     double oldProgress = tip.getProgress();   // save old progress
     boolean wasRunning = tip.isRunning();
     boolean wasComplete = tip.isComplete();
+    boolean wasPending = tip.isOnlyCommitPending();
+    TaskAttemptID taskid = status.getTaskID();
+    
     // If the TIP is already completed and the task reports as SUCCEEDED then 
     // mark the task as KILLED.
     // In case of task with no promotion the task tracker will mark the task 
@@ -484,13 +703,6 @@
         this.jobtracker.getTaskTracker(status.getTaskTracker());
       String httpTaskLogLocation = null; 
 
-      if (state == TaskStatus.State.COMMIT_PENDING) {
-        JobWithTaskContext j = new JobWithTaskContext(this, tip, 
-                                                      status.getTaskID(),
-                                                      metrics);
-        jobtracker.addToCommitQueue(j);
-      }
-
       if (null != ttStatus){
         String host;
         if (NetUtils.getStaticResolution(ttStatus.getHost()) != null) {
@@ -506,36 +718,40 @@
       if (state == TaskStatus.State.SUCCEEDED) {
         taskEvent = new TaskCompletionEvent(
                                             taskCompletionEventTracker, 
-                                            status.getTaskID(),
+                                            taskid,
                                             tip.idWithinJob(),
-                                            status.getIsMap(),
+                                            status.getIsMap() &&
+                                            !tip.isCleanupTask() &&
+                                            !tip.isSetupTask(),
                                             TaskCompletionEvent.Status.SUCCEEDED,
                                             httpTaskLogLocation 
                                            );
         taskEvent.setTaskRunTime((int)(status.getFinishTime() 
                                        - status.getStartTime()));
         tip.setSuccessEventNumber(taskCompletionEventTracker); 
-      }
-      //For a failed task update the JT datastructures.For the task state where
-      //only the COMMIT is pending, delegate everything to the JT thread. For
-      //failed tasks we want the JT to schedule a reexecution ASAP (and not go
-      //via the queue for the datastructures' updates).
-      else if (state == TaskStatus.State.COMMIT_PENDING) {
+      } else if (state == TaskStatus.State.COMMIT_PENDING) {
+        // If it is the first attempt reporting COMMIT_PENDING
+        // ask the task to commit.
+        if (!wasComplete && !wasPending) {
+          tip.doCommit(taskid);
+        }
         return;
-      } else if (state == TaskStatus.State.FAILED ||
-                 state == TaskStatus.State.KILLED) {
+      }
+      //For a failed task update the JT datastructures. 
+      else if (state == TaskStatus.State.FAILED ||
+               state == TaskStatus.State.KILLED) {
         // Get the event number for the (possibly) previously successful
         // task. If there exists one, then set that status to OBSOLETE 
         int eventNumber;
         if ((eventNumber = tip.getSuccessEventNumber()) != -1) {
           TaskCompletionEvent t = 
             this.taskCompletionEvents.get(eventNumber);
-          if (t.getTaskAttemptId().equals(status.getTaskID()))
+          if (t.getTaskAttemptId().equals(taskid))
             t.setTaskStatus(TaskCompletionEvent.Status.OBSOLETE);
         }
         
         // Tell the job to fail the relevant task
-        failedTask(tip, status.getTaskID(), status, ttStatus,
+        failedTask(tip, taskid, status, ttStatus,
                    wasRunning, wasComplete, metrics);
 
         // Did the task failure lead to tip failure?
@@ -547,9 +763,11 @@
           taskCompletionStatus = TaskCompletionEvent.Status.TIPFAILED;
         }
         taskEvent = new TaskCompletionEvent(taskCompletionEventTracker, 
-                                            status.getTaskID(),
+                                            taskid,
                                             tip.idWithinJob(),
-                                            status.getIsMap(),
+                                            status.getIsMap() &&
+                                            !tip.isCleanupTask() &&
+                                            !tip.isSetupTask(),
                                             taskCompletionStatus, 
                                             httpTaskLogLocation
                                            );
@@ -577,21 +795,24 @@
       LOG.debug("Taking progress for " + tip.getTIPId() + " from " + 
                  oldProgress + " to " + tip.getProgress());
     }
-    double progressDelta = tip.getProgress() - oldProgress;
-    if (tip.isMapTask()) {
-      if (maps.length == 0) {
-        this.status.setMapProgress(1.0f);
-      } else {
-        this.status.setMapProgress((float) (this.status.mapProgress() +
-                                            progressDelta / maps.length));
-      }
-    } else {
-      if (reduces.length == 0) {
-        this.status.setReduceProgress(1.0f);
+    
+    if (!tip.isCleanupTask() && !tip.isSetupTask()) {
+      double progressDelta = tip.getProgress() - oldProgress;
+      if (tip.isMapTask()) {
+        if (maps.length == 0) {
+          this.status.setMapProgress(1.0f);
+        } else {
+          this.status.setMapProgress((float) (this.status.mapProgress() +
+                                              progressDelta / maps.length));
+        }
       } else {
-        this.status.setReduceProgress
-          ((float) (this.status.reduceProgress() +
-                    (progressDelta / reduces.length)));
+        if (reduces.length == 0) {
+          this.status.setReduceProgress(1.0f);
+        } else {
+          this.status.setReduceProgress
+            ((float) (this.status.reduceProgress() +
+                      (progressDelta / reduces.length)));
+        }
       }
     }
   }
@@ -623,7 +844,7 @@
    *  Returns the total job counters, by adding together the job, 
    *  the map and the reduce counters.
    */
-  public Counters getCounters() {
+  public synchronized Counters getCounters() {
     Counters result = new Counters();
     result.incrAllCounters(getJobCounters());
     incrementTaskCounters(result, maps);
@@ -654,7 +875,7 @@
                                             int clusterSize, 
                                             int numUniqueHosts
                                            ) throws IOException {
-    if (!tasksInited) {
+    if (status.getRunState() != JobStatus.RUNNING) {
       LOG.info("Cannot create task split for " + profile.getJobID());
       return null;
     }
@@ -667,20 +888,156 @@
     
     Task result = maps[target].getTaskToRun(tts.getTrackerName());
     if (result != null) {
-      runningMapTasks += 1;
-      if (maps[target].isFirstAttempt(result.getTaskID())) {
-        JobHistory.Task.logStarted(maps[target].getTIPId(), Values.MAP.name(),
-                                   System.currentTimeMillis(),
-                                   maps[target].getSplitNodes());
-      }
-
-      jobCounters.incrCounter(Counter.TOTAL_LAUNCHED_MAPS, 1);
+      addRunningTaskToTIP(maps[target], result.getTaskID(), tts, true);
     }
 
     return result;
   }    
 
   /**
+   * Return a CleanupTask, if appropriate, to run on the given tasktracker
+   * 
+   */
+  public Task obtainCleanupTask(TaskTrackerStatus tts, 
+                                             int clusterSize, 
+                                             int numUniqueHosts,
+                                             boolean isMapSlot
+                                            ) throws IOException {
+    if(!tasksInited.get()) {
+      return null;
+    }
+    
+    synchronized(this) {
+      if (!canLaunchCleanupTask()) {
+        return null;
+      }
+      
+      String taskTracker = tts.getTrackerName();
+      // Update the last-known clusterSize
+      this.clusterSize = clusterSize;
+      if (!shouldRunOnTaskTracker(taskTracker)) {
+        return null;
+      }
+      
+      List<TaskInProgress> cleanupTaskList = new ArrayList<TaskInProgress>();
+      if (isMapSlot) {
+        cleanupTaskList.add(cleanup[0]);
+      } else {
+        cleanupTaskList.add(cleanup[1]);
+      }
+      TaskInProgress tip = findTaskFromList(cleanupTaskList,
+                             tts, numUniqueHosts, false);
+      if (tip == null) {
+        return null;
+      }
+      
+      // Now launch the cleanupTask
+      Task result = tip.getTaskToRun(tts.getTrackerName());
+      if (result != null) {
+        addRunningTaskToTIP(tip, result.getTaskID(), tts, true);
+      }
+      return result;
+    }
+    
+  }
+  
+  /**
+   * Check whether cleanup task can be launched for the job.
+   * 
+   * Cleanup task can be launched if it is not already launched
+   * or job is Killed
+   * or all maps and reduces are complete
+   * @return true/false
+   */
+  private synchronized boolean canLaunchCleanupTask() {
+    if (!tasksInited.get()) {
+      return false;
+    }
+    // check if the job is running
+    if (status.getRunState() != JobStatus.RUNNING &&
+        status.getRunState() != JobStatus.PREP) {
+      return false;
+    }
+    // check if cleanup task has been launched already. 
+    if (launchedCleanup) {
+      return false;
+    }
+    // check if job has failed or killed
+    if (jobKilled || jobFailed) {
+      return true;
+    }
+    // Check if all maps and reducers have finished.
+    boolean launchCleanupTask = 
+        ((finishedMapTasks + failedMapTIPs) == (numMapTasks));
+    if (launchCleanupTask) {
+      launchCleanupTask = 
+        ((finishedReduceTasks + failedReduceTIPs) == numReduceTasks);
+    }
+    return launchCleanupTask;
+  }
+
+  /**
+   * Return a SetupTask, if appropriate, to run on the given tasktracker
+   * 
+   */
+  public Task obtainSetupTask(TaskTrackerStatus tts, 
+                                             int clusterSize, 
+                                             int numUniqueHosts,
+                                             boolean isMapSlot
+                                            ) throws IOException {
+    if(!tasksInited.get()) {
+      return null;
+    }
+    
+    synchronized(this) {
+      if (!canLaunchSetupTask()) {
+        return null;
+      }
+      
+      String taskTracker = tts.getTrackerName();
+      // Update the last-known clusterSize
+      this.clusterSize = clusterSize;
+      if (!shouldRunOnTaskTracker(taskTracker)) {
+        return null;
+      }
+      
+      List<TaskInProgress> setupTaskList = new ArrayList<TaskInProgress>();
+      if (isMapSlot) {
+        setupTaskList.add(setup[0]);
+      } else {
+        setupTaskList.add(setup[1]);
+      }
+      TaskInProgress tip = findTaskFromList(setupTaskList,
+                             tts, numUniqueHosts, false);
+      if (tip == null) {
+        return null;
+      }
+      
+      // Now launch the setupTask
+      Task result = tip.getTaskToRun(tts.getTrackerName());
+      if (result != null) {
+        addRunningTaskToTIP(tip, result.getTaskID(), tts, true);
+      }
+      return result;
+    }
+  }
+  
+  /**
+   * Check whether setup task can be launched for the job.
+   * 
+   * Setup task can be launched after the tasks are inited
+   * and Job is in PREP state
+   * and if it is not already launched
+   * or job is not Killed/Failed
+   * @return true/false
+   */
+  private synchronized boolean canLaunchSetupTask() {
+    return (tasksInited.get() && status.getRunState() == JobStatus.PREP && 
+           !launchedSetup && !jobKilled && !jobFailed);
+  }
+  
+
+  /**
    * Return a ReduceTask, if appropriate, to run on the given tasktracker.
    * We don't have cache-sensitivity for reduce tasks, as they
    *  work on temporary MapRed files.  
@@ -689,7 +1046,7 @@
                                                int clusterSize,
                                                int numUniqueHosts
                                               ) throws IOException {
-    if (!tasksInited) {
+    if (status.getRunState() != JobStatus.RUNNING) {
       LOG.info("Cannot create task split for " + profile.getJobID());
       return null;
     }
@@ -702,19 +1059,128 @@
     
     Task result = reduces[target].getTaskToRun(tts.getTrackerName());
     if (result != null) {
-      runningReduceTasks += 1;
-      if (reduces[target].isFirstAttempt(result.getTaskID())) {
-        JobHistory.Task.logStarted(reduces[target].getTIPId(), Values.REDUCE.name(),
-                                   System.currentTimeMillis(), "");
-      }
-
-      jobCounters.incrCounter(Counter.TOTAL_LAUNCHED_REDUCES, 1);
+      addRunningTaskToTIP(reduces[target], result.getTaskID(), tts, true);
     }
 
     return result;
   }
+  
+  // returns the (cache)level at which the nodes matches
+  private int getMatchingLevelForNodes(Node n1, Node n2) {
+    int count = 0;
+    do {
+      if (n1.equals(n2)) {
+        return count;
+      }
+      ++count;
+      n1 = n1.getParent();
+      n2 = n2.getParent();
+    } while (n1 != null);
+    return this.maxLevel;
+  }
+
+  /**
+   * Populate the data structures as a task is scheduled.
+   * @param tip The tip for which the task is added
+   * @param id The attempt-id for the task
+   * @param tts task-tracker status
+   * @param isScheduled Whether this task is scheduled from the JT or has 
+   *        joined back upon restart
+   */
+  synchronized void addRunningTaskToTIP(TaskInProgress tip, TaskAttemptID id, 
+                                        TaskTrackerStatus tts, 
+                                        boolean isScheduled) {
+    // keeping the earlier ordering intact
+    String name;
+    String splits = "";
+    Enum counter = null;
+    if (tip.isSetupTask()) {
+      launchedSetup = true;
+      name = Values.SETUP.name();
+    } else if (tip.isCleanupTask()) {
+      launchedCleanup = true;
+      name = Values.CLEANUP.name();
+    } else if (tip.isMapTask()) {
+      ++runningMapTasks;
+      name = Values.MAP.name();
+      counter = Counter.TOTAL_LAUNCHED_MAPS;
+      splits = tip.getSplitNodes();
+      if (tip.getActiveTasks().size() > 1)
+        speculativeMapTasks++;
+    } else {
+      ++runningReduceTasks;
+      name = Values.REDUCE.name();
+      counter = Counter.TOTAL_LAUNCHED_REDUCES;
+      if (tip.getActiveTasks().size() > 1)
+        speculativeReduceTasks++;
+    }
+    // Note that the logs are for the scheduled tasks only. Tasks that join on 
+    // restart has already their logs in place.
+    if (tip.isFirstAttempt(id)) {
+      JobHistory.Task.logStarted(tip.getTIPId(), name,
+                                 tip.getExecStartTime(), splits);
+    }
+    if (!tip.isSetupTask() && !tip.isCleanupTask()) {
+      jobCounters.incrCounter(counter, 1);
+    }
+    
+    // Make an entry in the tip if the attempt is not scheduled i.e externally
+    // added
+    if (!isScheduled) {
+      tip.addRunningTask(id, tts.getTrackerName());
+    }
+
+    //TODO The only problem with these counters would be on restart.
+    // The jobtracker updates the counter only when the task that is scheduled
+    // if from a non-running tip and is local (data, rack ...). But upon restart
+    // as the reports come from the task tracker, there is no good way to infer
+    // when exactly to increment the locality counters. The only solution is to 
+    // increment the counters for all the tasks irrespective of 
+    //    - whether the tip is running or not
+    //    - whether its a speculative task or not
+    //
+    // So to simplify, increment the data locality counter whenever there is 
+    // data locality.
+    if (tip.isMapTask() && !tip.isSetupTask() && !tip.isCleanupTask()) {
+      // increment the data locality counter for maps
+      Node tracker = jobtracker.getNode(tts.getHost());
+      int level = this.maxLevel;
+      // find the right level across split locations
+      for (String local : maps[tip.getIdWithinJob()].getSplitLocations()) {
+        Node datanode = jobtracker.getNode(local);
+        int newLevel = this.maxLevel;
+        if (tracker != null && datanode != null) {
+          newLevel = getMatchingLevelForNodes(tracker, datanode);
+        }
+        if (newLevel < level) {
+          level = newLevel;
+          // an optimization
+          if (level == 0) {
+            break;
+          }
+        }
+      }
+      switch (level) {
+      case 0 :
+        LOG.info("Choosing data-local task " + tip.getTIPId());
+        jobCounters.incrCounter(Counter.DATA_LOCAL_MAPS, 1);
+        break;
+      case 1:
+        LOG.info("Choosing rack-local task " + tip.getTIPId());
+        jobCounters.incrCounter(Counter.RACK_LOCAL_MAPS, 1);
+        break;
+      default :
+        // check if there is any locality
+        if (level != this.maxLevel) {
+          LOG.info("Choosing cached task at level " + level + tip.getTIPId());
+          jobCounters.incrCounter(Counter.OTHER_LOCAL_MAPS, 1);
+        }
+        break;
+      }
+    }
+  }
     
-  private String convertTrackerNameToHostName(String trackerName) {
+  static String convertTrackerNameToHostName(String trackerName) {
     // Ugly!
     // Convert the trackerName to it's host name
     int indexOfColon = trackerName.indexOf(":");
@@ -1056,6 +1522,18 @@
     Node node = jobtracker.getNode(tts.getHost());
     Node nodeParentAtMaxLevel = null;
     
+
+    long outSize = resourceEstimator.getEstimatedMapOutputSize();
+    long availSpace = tts.getResourceStatus().getAvailableSpace();
+    if(availSpace < outSize) {
+      LOG.warn("No room for map task. Node " + node + 
+               " has " + availSpace + 
+               " bytes free; but we expect map to take " + outSize);
+
+      return -1; //see if a different TIP might work better. 
+    }
+    
+    
     // For scheduling a map task, we have two caches and a list (optional)
     //  I)   one for non-running task
     //  II)  one for running task (this is for handling speculation)
@@ -1094,18 +1572,6 @@
               nonRunningMapCache.remove(key);
             }
 
-            if (level == 0) {
-              LOG.info("Choosing data-local task " + tip.getTIPId());
-              jobCounters.incrCounter(Counter.DATA_LOCAL_MAPS, 1);
-            } else if (level == 1){
-              LOG.info("Choosing rack-local task " + tip.getTIPId());
-              jobCounters.incrCounter(Counter.RACK_LOCAL_MAPS, 1);
-            } else {
-              LOG.info("Choosing cached task at level " + level 
-                       + tip.getTIPId());
-              jobCounters.incrCounter(Counter.OTHER_LOCAL_MAPS, 1);
-            }
-
             return tip.getIdWithinJob();
           }
         }
@@ -1177,16 +1643,6 @@
               if (cacheForLevel.size() == 0) {
                 runningMapCache.remove(key);
               }
-              if (level == 0) {
-                LOG.info("Choosing a data-local task " + tip.getTIPId() 
-                         + " for speculation");
-              } else if (level == 1){
-                LOG.info("Choosing a rack-local task " + tip.getTIPId() 
-                         + " for speculation");
-              } else {
-                LOG.info("Choosing a cached task at level " + level
-                         + tip.getTIPId() + " for speculation");
-              }
               return tip.getIdWithinJob();
             }
           }
@@ -1252,6 +1708,16 @@
       return -1;
     }
 
+    long outSize = resourceEstimator.getEstimatedReduceInputSize();
+    long availSpace = tts.getResourceStatus().getAvailableSpace();
+    if(availSpace < outSize) {
+      LOG.warn("No room for reduce task. Node " + taskTracker + " has " +
+                availSpace + 
+               " bytes free; but we expect reduce input to take " + outSize);
+
+      return -1; //see if a different TIP might work better. 
+    }
+    
     // 1. check for a never-executed reduce tip
     // reducers don't have a cache and so pass -1 to explicitly call that out
     tip = findTaskFromList(nonRunningReduces, tts, numUniqueHosts, false);
@@ -1296,9 +1762,10 @@
    */
   public synchronized boolean completedTask(TaskInProgress tip, 
                                          TaskStatus status,
-                                         JobTrackerMetrics metrics) 
+                                         JobTrackerInstrumentation metrics) 
   {
     TaskAttemptID taskid = status.getTaskID();
+    int oldNumAttempts = tip.getActiveTasks().size();
         
     // Sanity check: is the TIP already complete? 
     // It _is_ safe to not decrement running{Map|Reduce}Tasks and
@@ -1322,125 +1789,229 @@
 
     // Mark the TIP as complete
     tip.completed(taskid);
+    resourceEstimator.updateWithCompletedTask(status, tip);
 
     // Update jobhistory 
-    String taskTrackerName = jobtracker.getNode(jobtracker.getTaskTracker(
-                               status.getTaskTracker()).getHost()).toString();
+    TaskTrackerStatus ttStatus = 
+      this.jobtracker.getTaskTracker(status.getTaskTracker());
+    String trackerHostname = jobtracker.getNode(ttStatus.getHost()).toString();
+    String taskType = tip.isCleanupTask() ? Values.CLEANUP.name() :
+                      tip.isSetupTask() ? Values.SETUP.name() :
+                      tip.isMapTask() ? Values.MAP.name() : 
+                      Values.REDUCE.name();
     if (status.getIsMap()){
       JobHistory.MapAttempt.logStarted(status.getTaskID(), status.getStartTime(), 
-                                       taskTrackerName); 
+                                       status.getTaskTracker(), 
+                                       ttStatus.getHttpPort(), 
+                                       taskType); 
       JobHistory.MapAttempt.logFinished(status.getTaskID(), status.getFinishTime(), 
-                                        taskTrackerName); 
-      JobHistory.Task.logFinished(tip.getTIPId(), 
-                                  Values.MAP.name(), status.getFinishTime(),
-                                  status.getCounters()); 
+                                        trackerHostname, taskType,
+                                        status.getStateString(), 
+                                        status.getCounters()); 
     }else{
       JobHistory.ReduceAttempt.logStarted( status.getTaskID(), status.getStartTime(), 
-                                          taskTrackerName); 
+                                          status.getTaskTracker(),
+                                          ttStatus.getHttpPort(), 
+                                          taskType); 
       JobHistory.ReduceAttempt.logFinished(status.getTaskID(), status.getShuffleFinishTime(),
                                            status.getSortFinishTime(), status.getFinishTime(), 
-                                           taskTrackerName); 
-      JobHistory.Task.logFinished(tip.getTIPId(), 
-                                  Values.REDUCE.name(), status.getFinishTime(),
-                                  status.getCounters()); 
-    }
+                                           trackerHostname, 
+                                           taskType,
+                                           status.getStateString(), 
+                                           status.getCounters()); 
+    }
+    JobHistory.Task.logFinished(tip.getTIPId(), 
+                                taskType,
+                                tip.getExecFinishTime(),
+                                status.getCounters()); 
         
-    // Update the running/finished map/reduce counts
-    if (tip.isMapTask()){
+    int newNumAttempts = tip.getActiveTasks().size();
+    if (tip.isSetupTask()) {
+      // setup task has finished. kill the extra setup tip
+      killSetupTip(!tip.isMapTask());
+      // Job can start running now.
+      this.status.setSetupProgress(1.0f);
+      this.status.setRunState(JobStatus.RUNNING);
+      JobHistory.JobInfo.logStarted(profile.getJobID());
+    } else if (tip.isCleanupTask()) {
+      // cleanup task has finished. Kill the extra cleanup tip
+      if (tip.isMapTask()) {
+        // kill the reduce tip
+        cleanup[1].kill();
+      } else {
+        cleanup[0].kill();
+      }
+      //
+      // The Job is done
+      // if the job is failed, then mark the job failed.
+      if (jobFailed) {
+        terminateJob(JobStatus.FAILED);
+      }
+      // if the job is killed, then mark the job killed.
+      if (jobKilled) {
+        terminateJob(JobStatus.KILLED);
+      }
+      else {
+        jobComplete(metrics);
+      }
+      // The job has been killed/failed/successful
+      // JobTracker should cleanup this task
+      jobtracker.markCompletedTaskAttempt(status.getTaskTracker(), taskid);
+    } else if (tip.isMapTask()) {
       runningMapTasks -= 1;
+      // check if this was a sepculative task
+      if (oldNumAttempts > 1) {
+        speculativeMapTasks -= (oldNumAttempts - newNumAttempts);
+      }
       finishedMapTasks += 1;
-      metrics.completeMap();
+      metrics.completeMap(taskid);
       // remove the completed map from the resp running caches
       retireMap(tip);
-    } else{
+      if ((finishedMapTasks + failedMapTIPs) == (numMapTasks)) {
+        this.status.setMapProgress(1.0f);
+      }
+    } else {
       runningReduceTasks -= 1;
+      if (oldNumAttempts > 1) {
+        speculativeReduceTasks -= (oldNumAttempts - newNumAttempts);
+      }
       finishedReduceTasks += 1;
-      metrics.completeReduce();
+      metrics.completeReduce(taskid);
       // remove the completed reduces from the running reducers set
       retireReduce(tip);
-    }
-        
-    //
-    // Figure out whether the Job is done
-    //
-    isJobComplete(tip, metrics);
-    
-    if (this.status.getRunState() != JobStatus.RUNNING) {
-      // The job has been killed/failed, 
-      // JobTracker should cleanup this task
-      jobtracker.markCompletedTaskAttempt(status.getTaskTracker(), taskid);
-      return false;
+      if ((finishedReduceTasks + failedReduceTIPs) == (numReduceTasks)) {
+        this.status.setReduceProgress(1.0f);
+      }
     }
     
     return true;
   }
 
   /**
-   * Check if the job is done since all it's component tasks are either
+   * The job is done since all it's component tasks are either
    * successful or have failed.
    * 
-   * @param tip the current tip which completed either succesfully or failed
    * @param metrics job-tracker metrics
-   * @return
    */
-  private boolean isJobComplete(TaskInProgress tip, JobTrackerMetrics metrics) {
-    // Job is complete if total-tips = finished-tips + failed-tips
-    boolean allDone = 
-      ((finishedMapTasks + failedMapTIPs) == numMapTasks);
-    if (allDone) {
-      if (tip.isMapTask()) {
-        this.status.setMapProgress(1.0f);              
-      }
-      allDone = 
-        ((finishedReduceTasks + failedReduceTIPs) == numReduceTasks);
-    }
-
+  private void jobComplete(JobTrackerInstrumentation metrics) {
     //
-    // If all tasks are complete, then the job is done!
+    // All tasks are complete, then the job is done!
     //
-    if (this.status.getRunState() == JobStatus.RUNNING && allDone) {
+    if (this.status.getRunState() == JobStatus.RUNNING ) {
       this.status.setRunState(JobStatus.SUCCEEDED);
-      this.status.setReduceProgress(1.0f);
+      this.status.setCleanupProgress(1.0f);
       this.finishTime = System.currentTimeMillis();
-      garbageCollect();
       LOG.info("Job " + this.status.getJobID() + 
                " has completed successfully.");
       JobHistory.JobInfo.logFinished(this.status.getJobID(), finishTime, 
                                      this.finishedMapTasks, 
                                      this.finishedReduceTasks, failedMapTasks, 
                                      failedReduceTasks, getCounters());
-      metrics.completeJob();
-      return true;
+      // Note that finalize will close the job history handles which garbage collect
+      // might try to finalize
+      garbageCollect();
+      
+      metrics.completeJob(this.conf, this.status.getJobID());
+    }
+  }
+  
+  private synchronized void terminateJob(int jobTerminationState) {
+    if ((status.getRunState() == JobStatus.RUNNING) ||
+        (status.getRunState() == JobStatus.PREP)) {
+      if (jobTerminationState == JobStatus.FAILED) {
+        this.status = new JobStatus(status.getJobID(),
+                                    1.0f, 1.0f, 1.0f, JobStatus.FAILED,
+                                    status.getJobPriority());
+        this.finishTime = System.currentTimeMillis();
+        JobHistory.JobInfo.logFailed(this.status.getJobID(), finishTime, 
+                                     this.finishedMapTasks, 
+                                     this.finishedReduceTasks);
+      } else {
+        this.status = new JobStatus(status.getJobID(),
+                                    1.0f, 1.0f, 1.0f, JobStatus.KILLED,
+                                    status.getJobPriority());
+        this.finishTime = System.currentTimeMillis();
+        JobHistory.JobInfo.logKilled(this.status.getJobID(), finishTime, 
+                                     this.finishedMapTasks, 
+                                     this.finishedReduceTasks);
+      }
+      garbageCollect();
     }
-    
-    return false;
   }
+
   /**
-   * Kill the job and all its component tasks.
-   */
-  public synchronized void kill() {
+   * Terminate the job and all its component tasks.
+   * Calling this will lead to marking the job as failed/killed. Cleanup 
+   * tip will be launched. If the job has not inited, it will directly call 
+   * terminateJob as there is no need to launch cleanup tip.
+   * This method is reentrant.
+   * @param jobTerminationState job termination state
+   */
+  private synchronized void terminate(int jobTerminationState) {
+    if(!tasksInited.get()) {
+    	//init could not be done, we just terminate directly.
+      terminateJob(jobTerminationState);
+      return;
+    }
+
     if ((status.getRunState() == JobStatus.RUNNING) ||
          (status.getRunState() == JobStatus.PREP)) {
       LOG.info("Killing job '" + this.status.getJobID() + "'");
-      this.status = new JobStatus(status.getJobID(), 1.0f, 1.0f, JobStatus.FAILED);
-      this.finishTime = System.currentTimeMillis();
-      this.runningMapTasks = 0;
-      this.runningReduceTasks = 0;
+      if (jobTerminationState == JobStatus.FAILED) {
+        if(jobFailed) {//reentrant
+          return;
+        }
+        jobFailed = true;
+      } else if (jobTerminationState == JobStatus.KILLED) {
+        if(jobKilled) {//reentrant
+          return;
+        }
+        jobKilled = true;
+      }
       //
       // kill all TIPs.
       //
+      for (int i = 0; i < setup.length; i++) {
+        setup[i].kill();
+      }
       for (int i = 0; i < maps.length; i++) {
         maps[i].kill();
       }
       for (int i = 0; i < reduces.length; i++) {
         reduces[i].kill();
       }
-      JobHistory.JobInfo.logFailed(this.status.getJobID(), finishTime, 
-                                   this.finishedMapTasks, this.finishedReduceTasks);
-      garbageCollect();
     }
   }
-
+  
+  /**
+   * Kill the job and all its component tasks. This method is called from 
+   * jobtracker and should return fast as it locks the jobtracker.
+   */
+  public void kill() {
+    boolean killNow = false;
+    synchronized(jobInitKillStatus) {
+      if(jobInitKillStatus.killed) {//job is already marked for killing
+        return;
+      }
+      jobInitKillStatus.killed = true;
+      //if not in middle of init, terminate it now
+      if(!jobInitKillStatus.initStarted || jobInitKillStatus.initDone) {
+        //avoiding nested locking by setting flag
+        killNow = true;
+      }
+    }
+    if(killNow) {
+      terminate(JobStatus.KILLED);
+    }
+  }
+  
+  /**
+   * Fails the job and all its component tasks.
+   */
+  synchronized void fail() {
+    terminate(JobStatus.FAILED);
+  }
+  
   /**
    * A task assigned to this JobInProgress has reported in as failed.
    * Most of the time, we'll just reschedule execution.  However, after
@@ -1457,7 +2028,7 @@
                           TaskStatus status, 
                           TaskTrackerStatus taskTrackerStatus,
                           boolean wasRunning, boolean wasComplete,
-                          JobTrackerMetrics metrics) {
+                          JobTrackerInstrumentation metrics) {
     // check if the TIP is already failed
     boolean wasFailed = tip.isFailed();
 
@@ -1469,7 +2040,11 @@
         
     //update running  count on task failure.
     if (wasRunning && !isRunning) {
-      if (tip.isMapTask()){
+      if (tip.isCleanupTask()) {
+        launchedCleanup = false;
+      } else if (tip.isSetupTask()) {
+        launchedSetup = false;
+      } else if (tip.isMapTask()) {
         runningMapTasks -= 1;
         // remove from the running queue and put it in the non-running cache
         // if the tip is not complete i.e if the tip still needs to be run
@@ -1504,36 +2079,48 @@
     }
         
     // update job history
-    String taskTrackerName = jobtracker.getNode(
-                               taskTrackerStatus.getHost()).toString();
+    String taskTrackerName = taskTrackerStatus.getHost();
+    long finishTime = status.getFinishTime();
+    String taskType = tip.isCleanupTask() ? Values.CLEANUP.name() :
+                      tip.isSetupTask() ? Values.SETUP.name() :
+                      tip.isMapTask() ? Values.MAP.name() : 
+                      Values.REDUCE.name();
     if (status.getIsMap()) {
       JobHistory.MapAttempt.logStarted(status.getTaskID(), status.getStartTime(), 
-                taskTrackerName);
+          status.getTaskTracker(), taskTrackerStatus.getHttpPort(), 
+          taskType);
       if (status.getRunState() == TaskStatus.State.FAILED) {
-        JobHistory.MapAttempt.logFailed(status.getTaskID(), System.currentTimeMillis(),
-                taskTrackerName, status.getDiagnosticInfo());
+        JobHistory.MapAttempt.logFailed(status.getTaskID(), finishTime,
+                taskTrackerName, status.getDiagnosticInfo(), 
+                taskType);
       } else {
-        JobHistory.MapAttempt.logKilled(status.getTaskID(), System.currentTimeMillis(),
-                taskTrackerName, status.getDiagnosticInfo());
+        JobHistory.MapAttempt.logKilled(status.getTaskID(), finishTime,
+                taskTrackerName, status.getDiagnosticInfo(),
+                taskType);
       }
     } else {
       JobHistory.ReduceAttempt.logStarted(status.getTaskID(), status.getStartTime(), 
-                taskTrackerName);
+          status.getTaskTracker(), taskTrackerStatus.getHttpPort(), 
+          taskType);
       if (status.getRunState() == TaskStatus.State.FAILED) {
-        JobHistory.ReduceAttempt.logFailed(status.getTaskID(), System.currentTimeMillis(),
-                taskTrackerName, status.getDiagnosticInfo());
+        JobHistory.ReduceAttempt.logFailed(status.getTaskID(), finishTime,
+                taskTrackerName, status.getDiagnosticInfo(), 
+                taskType);
       } else {
-        JobHistory.ReduceAttempt.logKilled(status.getTaskID(), System.currentTimeMillis(),
-                taskTrackerName, status.getDiagnosticInfo());
+        JobHistory.ReduceAttempt.logKilled(status.getTaskID(), finishTime,
+                taskTrackerName, status.getDiagnosticInfo(), 
+                taskType);
       }
     }
         
     // After this, try to assign tasks with the one after this, so that
     // the failed task goes to the end of the list.
-    if (tip.isMapTask()) {
-      failedMapTasks++; 
-    } else {
-      failedReduceTasks++; 
+    if (!tip.isCleanupTask() && !tip.isSetupTask()) {
+      if (tip.isMapTask()) {
+        failedMapTasks++;
+      } else {
+        failedReduceTasks++; 
+      }
     }
             
     //
@@ -1558,40 +2145,55 @@
       // Allow upto 'mapFailuresPercent' of map tasks to fail or
       // 'reduceFailuresPercent' of reduce tasks to fail
       //
-      boolean killJob = 
-        tip.isMapTask() ? 
+      boolean killJob = tip.isCleanupTask() || tip.isSetupTask() ? true :
+                        tip.isMapTask() ? 
             ((++failedMapTIPs*100) > (mapFailuresPercent*numMapTasks)) :
             ((++failedReduceTIPs*100) > (reduceFailuresPercent*numReduceTasks));
       
       if (killJob) {
         LOG.info("Aborting job " + profile.getJobID());
         JobHistory.Task.logFailed(tip.getTIPId(), 
-                                  tip.isMapTask() ? 
-                                          Values.MAP.name() : 
-                                          Values.REDUCE.name(),  
-                                  System.currentTimeMillis(), 
+                                  taskType,  
+                                  status.getFinishTime(), 
                                   status.getDiagnosticInfo());
-        JobHistory.JobInfo.logFailed(profile.getJobID(), 
-                                     System.currentTimeMillis(), 
-                                     this.finishedMapTasks, 
-                                     this.finishedReduceTasks
-                                    );
-        kill();
-      } else {
-        isJobComplete(tip, metrics);
+        if (tip.isCleanupTask()) {
+          // kill the other tip
+          if (tip.isMapTask()) {
+            cleanup[1].kill();
+          } else {
+            cleanup[0].kill();
+          }
+          terminateJob(JobStatus.FAILED);
+        } else {
+          if (tip.isSetupTask()) {
+            // kill the other tip
+            killSetupTip(!tip.isMapTask());
+          }
+          fail();
+        }
       }
       
       //
       // Update the counters
       //
-      if (tip.isMapTask()) {
-        jobCounters.incrCounter(Counter.NUM_FAILED_MAPS, 1);
-      } else {
-        jobCounters.incrCounter(Counter.NUM_FAILED_REDUCES, 1);
+      if (!tip.isCleanupTask() && !tip.isSetupTask()) {
+        if (tip.isMapTask()) {
+          jobCounters.incrCounter(Counter.NUM_FAILED_MAPS, 1);
+        } else {
+          jobCounters.incrCounter(Counter.NUM_FAILED_REDUCES, 1);
+        }
       }
     }
   }
 
+  void killSetupTip(boolean isMap) {
+    if (isMap) {
+      setup[0].kill();
+    } else {
+      setup[1].kill();
+    }
+  }
+
   /**
    * Fail a task with a given reason, but without a status object.
    * @param tip The task's tip
@@ -1601,7 +2203,7 @@
    */
   public void failedTask(TaskInProgress tip, TaskAttemptID taskid, String reason, 
                          TaskStatus.Phase phase, TaskStatus.State state, 
-                         String trackerName, JobTrackerMetrics metrics) {
+                         String trackerName, JobTrackerInstrumentation metrics) {
     TaskStatus status = TaskStatus.createTaskStatus(tip.isMapTask(), 
                                                     taskid,
                                                     0.0f,
@@ -1610,10 +2212,13 @@
                                                     reason,
                                                     trackerName, phase,
                                                     null);
+    status.setFinishTime(System.currentTimeMillis());
     updateTaskStatus(tip, status, metrics);
     JobHistory.Task.logFailed(tip.getTIPId(), 
+                              tip.isCleanupTask() ? Values.CLEANUP.name() : 
+                              tip.isSetupTask() ? Values.SETUP.name() : 
                               tip.isMapTask() ? Values.MAP.name() : Values.REDUCE.name(), 
-                              System.currentTimeMillis(), reason); 
+                              tip.getExecFinishTime(), reason, taskid); 
   }
        
                            
@@ -1649,16 +2254,6 @@
       Path tempDir = new Path(jobtracker.getSystemDir(), jobId.toString());
       FileSystem fs = tempDir.getFileSystem(conf);
       fs.delete(tempDir, true); 
-
-      // delete the temporary directory in output directory
-      Path outputPath = FileOutputFormat.getOutputPath(conf);
-      if (outputPath != null) {
-        Path tmpDir = new Path(outputPath, MRConstants.TEMP_DIR_NAME);
-        FileSystem fileSys = tmpDir.getFileSystem(conf);
-        if (fileSys.exists(tmpDir)) {
-          fileSys.delete(tmpDir, true);
-        }
-      }
     } catch (IOException e) {
       LOG.warn("Error cleaning up "+profile.getJobID()+": "+e);
     }
@@ -1674,14 +2269,26 @@
   /**
    * Return the TaskInProgress that matches the tipid.
    */
-  public TaskInProgress getTaskInProgress(TaskID tipid){
+  public synchronized TaskInProgress getTaskInProgress(TaskID tipid) {
     if (tipid.isMap()) {
+      if (tipid.equals(cleanup[0].getTIPId())) { // cleanup map tip
+        return cleanup[0]; 
+      }
+      if (tipid.equals(setup[0].getTIPId())) { //setup map tip
+        return setup[0];
+      }
       for (int i = 0; i < maps.length; i++) {
         if (tipid.equals(maps[i].getTIPId())){
           return maps[i];
         }
       }
     } else {
+      if (tipid.equals(cleanup[1].getTIPId())) { // cleanup reduce tip
+        return cleanup[1]; 
+      }
+      if (tipid.equals(setup[1].getTIPId())) { //setup reduce tip
+        return setup[1];
+      }
       for (int i = 0; i < reduces.length; i++) {
         if (tipid.equals(reduces[i].getTIPId())){
           return reduces[i];
@@ -1696,7 +2303,7 @@
    * @param mapId the id of the map
    * @return the task status of the completed task
    */
-  public TaskStatus findFinishedMap(int mapId) {
+  public synchronized TaskStatus findFinishedMap(int mapId) {
     TaskInProgress tip = maps[mapId];
     if (tip.isComplete()) {
       TaskStatus[] statuses = tip.getTaskStatuses();
@@ -1708,6 +2315,10 @@
     }
     return null;
   }
+  
+  synchronized int getNumTaskCompletionEvents() {
+    return taskCompletionEvents.size();
+  }
     
   synchronized public TaskCompletionEvent[] getTaskCompletionEvents(
                                                                     int fromEventId, int maxEvents) {
@@ -1723,7 +2334,7 @@
   synchronized void fetchFailureNotification(TaskInProgress tip, 
                                              TaskAttemptID mapTaskId, 
                                              String trackerName, 
-                                             JobTrackerMetrics metrics) {
+                                             JobTrackerInstrumentation metrics) {
     Integer fetchFailures = mapTaskIdToFetchFailuresMap.get(mapTaskId);
     fetchFailures = (fetchFailures == null) ? 1 : (fetchFailures+1);
     mapTaskIdToFetchFailuresMap.put(mapTaskId, fetchFailures);
@@ -1749,29 +2360,39 @@
     }
   }
   
-  static class JobWithTaskContext {
-    private JobInProgress job;
-    private TaskInProgress tip;
-    private TaskAttemptID taskId;
-    private JobTrackerMetrics metrics;
-    JobWithTaskContext(JobInProgress job, TaskInProgress tip, 
-        TaskAttemptID taskId, JobTrackerMetrics metrics) {
-      this.job = job;
-      this.tip = tip;
-      this.taskId = taskId;
-      this.metrics = metrics;
-    }
-    JobInProgress getJob() {
-      return job;
-    }
-    TaskInProgress getTIP() {
-      return tip;
-    }
-    TaskAttemptID getTaskID() {
-      return taskId;
-    }
-    JobTrackerMetrics getJobTrackerMetrics() {
-      return metrics;
-    }
+  /**
+   * @return The JobID of this JobInProgress.
+   */
+  public JobID getJobID() {
+    return jobId;
+  }
+  
+  public synchronized Object getSchedulingInfo() {
+    return this.schedulingInfo;
+  }
+  
+  public synchronized void setSchedulingInfo(Object schedulingInfo) {
+    this.schedulingInfo = schedulingInfo;
+    this.status.setSchedulingInfo(schedulingInfo.toString());
+  }
+  
+  /**
+   * To keep track of kill and initTasks status of this job. initTasks() take 
+   * a lock on JobInProgress object. kill should avoid waiting on 
+   * JobInProgress lock since it may take a while to do initTasks().
+   */
+  private static class JobInitKillStatus {
+    //flag to be set if kill is called
+    boolean killed;
+    
+    boolean initStarted;
+    boolean initDone;
+  }
+
+  boolean isComplete() {
+    int runState = this.status.getRunState();
+    return runState == JobStatus.SUCCEEDED 
+           || runState == JobStatus.FAILED 
+           || runState == JobStatus.KILLED;
   }
 }
